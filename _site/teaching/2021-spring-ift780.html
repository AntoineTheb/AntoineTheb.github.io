

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>IFT780: Réseaux de neurones - Antoine Théberge</title>







<meta property="og:locale" content="en-CA">
<meta property="og:site_name" content="Antoine Théberge">
<meta property="og:title" content="IFT780: Réseaux de neurones">


  <link rel="canonical" href="https://www.antoinetheberge.ca/teaching/2021-spring-ift780">
  <meta property="og:url" content="https://www.antoinetheberge.ca/teaching/2021-spring-ift780">



  <meta property="og:description" content="Local: D3−2040 Périodes de cours:  Lundi 15:30−16:20, Mardi 15:30−17:20">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2021-01-03T00:00:00-08:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Antoine Théberge",
      "url" : "https://www.antoinetheberge.ca",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://www.antoinetheberge.ca/feed.xml" type="application/atom+xml" rel="alternate" title="Antoine Théberge Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://www.antoinetheberge.ca/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://www.antoinetheberge.ca/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://www.antoinetheberge.ca/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://www.antoinetheberge.ca/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://www.antoinetheberge.ca/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://www.antoinetheberge.ca/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://www.antoinetheberge.ca/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://www.antoinetheberge.ca/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://www.antoinetheberge.ca/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://www.antoinetheberge.ca/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://www.antoinetheberge.ca/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://www.antoinetheberge.ca/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://www.antoinetheberge.ca/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://www.antoinetheberge.ca/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://www.antoinetheberge.ca/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://www.antoinetheberge.ca/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://www.antoinetheberge.ca/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://www.antoinetheberge.ca/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://www.antoinetheberge.ca/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://www.antoinetheberge.ca/">Antoine Théberge</a></li>
          
            
            <li class="masthead__menu-item"><a href="/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="/talks/">Talks</a></li>
          
            
            <li class="masthead__menu-item"><a href="/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="/portfolio/">Portfolio</a></li>
          
            
            <li class="masthead__menu-item"><a href="/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="/cv/">CV</a></li>
          
            
            <li class="masthead__menu-item"><a href="/markdown/">Guide</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="/images/profile.jpg" class="author__avatar" alt="Antoine Théberge">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Antoine Théberge</h3>
    <p class="author__bio">[Mettre ici une bio courte et légèrement humoristique]</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Sherbrooke, Québec</li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Université de Sherbrooke</li>
      
      
      
      
       
      
        <li><a href="https://twitter.com/antoinetheb"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/antoinetheb"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=m5GXCssAAAAJ&hl"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
        <li><a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=antoine+théberge"><i class="ai ai-pubmed-square ai-fw"></i> PubMed</a></li>
      
      
        <li><a href="https://orcid.org/0000-0002-3959-8316"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="IFT780: Réseaux de neurones">
    <meta itemprop="description" content="Local: D3−2040 Périodes de cours:  Lundi 15:30−16:20, Mardi 15:30−17:20">
    <meta itemprop="datePublished" content="January 03, 2021">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">IFT780: Réseaux de neurones
</h1>
          
        
        
        
          <p> Graduate course, <i>Université de Sherbrooke, Faculté des Sciences, Département d'informatique</i>, 2021 </p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p><strong>Local</strong>: D3−2040 <br />
<strong>Périodes de cours</strong>:  Lundi 15:30−16:20, Mardi 15:30−17:20</p>

<h1 id="objectifs-du-cours">Objectifs du cours</h1>
<p><strong>Apprentissage supervisé par réseaux de neurones</strong> : classification et régression avec réseaux à propagation avant et prédiction de cibles. <strong>Réseaux de neurones classiques</strong> : perceptron multi-couches et régression logistique. <strong>Réseaux à convolution et architectures profondes (“deep learning”) modernes</strong> : VGG, InceptionNet, ResNet, UNet, etc. <strong>Applications à l’imagerie</strong> : reconnaissance, segmentation, localisation, transfert de style, etc. <strong>Réseaux de neurones récurrents et applications à l’analyse de texte et d’images. Modèles génératifs adversaires et réseaux de neurones non-supervisés</strong> : auto-encodeurs et auto-encodeurs variationnels. <strong>Bonnes pratiques</strong> : transfert d’entrainement, augmentation de données, normalisation, méthodes d’entrainement modernes, visualisation. <strong>Concepts avancés</strong>: modèles d’attention, autoML, compression, convolution dilatées.</p>

<h1 id="méthode-pédagogique">Méthode pédagogique</h1>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Thème</th>
      <th>Slides</th>
      <th>Lectures:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Concepts de base</td>
      <td><a href="/files/ift780/00_presentation.pdf">PDF</a></td>
      <td><a href="#9">[9]</a> : 6.1, 6.2, 6.3, 6.5, <a href="#27">[45]</a></td>
    </tr>
    <tr>
      <td>2</td>
      <td>Réseaux à convolution</td>
      <td> </td>
      <td><a href="#21">[21]</a> : 9.0 à 9.5 ; <a href="#27">[27]</a></td>
    </tr>
    <tr>
      <td>3</td>
      <td>Réseaux à convolution avancés et architectures convolutives modernes</td>
      <td> </td>
      <td>Réseaux à convolutions : <a href="#27">[27]</a> <a href="#26">[26]</a> <a href="#22">[22]</a> <a href="#45">[45]</a> <a href="#50">[50]</a> <a href="#43">[43]</a> <a href="#46">[46]</a> <a href="#17">[17]</a> <a href="#20">[20]</a> <a href="#19">[19]</a></td>
    </tr>
    <tr>
      <td>4</td>
      <td>Segmentation et localisation</td>
      <td> </td>
      <td>Segmentation et localisation : <a href="#48">[48]</a> <a href="#29">[29]</a> <a href="#1">[1]</a> <a href="#42">[42]</a> <a href="#32">[32]</a> <a href="#5">[5]</a> <a href="#23">[23]</a> <a href="#6">[6]</a> <a href="#34">[34]</a> <a href="#14">[14]</a> <a href="#13">[13]</a> <a href="#41">[41]</a> <a href="#39">[39]</a> <a href="#40">[40]</a> <a href="#28">[28]</a> <a href="#16">[16]</a></td>
    </tr>
    <tr>
      <td>5</td>
      <td>Matériel et bibliothèques de code</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>6</td>
      <td>Considérations pratiques</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>7</td>
      <td>Réseaux récurrents, attention et transformers</td>
      <td> </td>
      <td>Réseaux récurrents <a href="#31">[31]</a> <a href="#18">[18]</a> <a href="#8">[8]</a> Attention : <a href="#2">[2]</a> <a href="#30">[30]</a> <a href="#49">[49]</a> <a href="#7">[7]</a> Transformers : <a href="#47">[47]</a> <a href="#11">[11]</a> <a href="#37">[37]</a> <a href="#38">[38]</a> <a href="#4">[4]</a></td>
    </tr>
    <tr>
      <td>8</td>
      <td>Modèles génératifs</td>
      <td> </td>
      <td>Autoencodeurs : <a href="#25">[25]</a> <a href="#35">[35]</a> <a href="#44">[44]</a> <a href="#12">[12]</a> GANs : <a href="#15">[15]</a> <a href="#33">[33]</a> <a href="#36">[36]</a> <a href="#3">[3]</a> <a href="#24">[24]</a></td>
    </tr>
    <tr>
      <td>9</td>
      <td>Visualisation</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>10</td>
      <td>Optimisation d’hyper-paramètres</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>Le plan de cours complet est disponible ici: <a href="/files/ift780/ift780.pdf">plan de cours</a></p>

<h1 id="travaux-pratiques">Travaux pratiques</h1>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Nom</th>
      <th>Fichiers</th>
      <th>Énoncé</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Réseaux de neurones pleinement connectés</td>
      <td><a href="/files/ift780/TP1/TP1.zip">TP1.zip</a></td>
      <td><a href="/files/ift780/TP1/IFT780_TP1.pdf">PDF</a></td>
    </tr>
    <tr>
      <td>2</td>
      <td>Réseaux de neurones convolutifs</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>3</td>
      <td>Projet</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h1 id="ressources">Ressources</h1>
<p>Il n’est absolument pas nécessaire de consulter des ressources additionnelles aux diapositives présentées dans le cours en assistant aux séances. Par contre, si vous souhaitez consulter les livres sur lequel le cours est basé:</p>

<p><a href="#21">[21]</a> Deep Learning - Ian J. Goodfellow, Yoshua Bengio and Aaron Courville, MIT Press, 2016 <br />
<a href="#9">[9]</a> Pattern recognition and machine learning - Christopher M. Bishop, Springer, 2006</p>

<p>De plus, le livre suivant est très complet et pertinent pour les gens ayant un <em>background</em> moins mathématique:</p>

<p><a href="#51">[51]</a> Mathematics for Machine Learning - M. Deisenroth, A. Faisal, and C. Ong, Cambridge University Press, 2020</p>

<p>Ces livres sont disponibles à la bibliothèque du Frère Théode et sur commande à la coop de l’Université de Sherbrooke. <a href="#21">[21]</a> et <a href="#9">[9]</a> sont aussi disponibles en ligne.</p>

<h1 id="références">Références</h1>
<p><a href="https://arxiv.org/pdf/1511.00561.pdf">[1]<a name="1"></a> BADRINARAYANAN, VIJAY AND KENDALL, ALEX AND CIPOLLA, ROBERTO : Segnet : A deep convolutional encoderdecoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481–2495, 2017</a></p>

<p><a href="https://arxiv.org/pdf/1409.0473.pdf">[2]<a name="2"></a> BAHDANAU, DZMITRY AND CHO, KYUNGHYUN AND BENGIO, YOSHUA : Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv :1409.0473, 2014.</a></p>

<p><a href="https://arxiv.org/pdf/1809.11096.pdf&amp;org=deepmind">[3]<a name="3"></a> BROCK, ANDREW AND DONAHUE, JEFF AND SIMONYAN, KAREN : Large scale GAN training for high fidelity natural image synthesis. arXiv preprint arXiv :1809.11096, 2018.</a></p>

<p><a href="https://arxiv.org/pdf/2005.14165.pdf">[4]<a name="4"></a> BROWN, TOM B AND MANN, BENJAMIN AND RYDER, NICK AND SUBBIAH, MELANIE AND KAPLAN, JARED AND DHARIWAL, PRAFULLA AND NEELAKANTAN, ARVIND AND SHYAM, PRANAV AND SASTRY, GIRISH AND ASKELL, AMANDA AND OTHERS : Language models are few-shot learners. arXiv preprint arXiv :2005.14165, 2020.</a></p>

<p><a href="https://arxiv.org/pdf/1606.06650.pdf">[5]<a name="5"></a> ÇIÇEK, ÖZGÜN AND ABDULKADIR, AHMED AND LIENKAMP, SOEREN S AND BROX, THOMAS AND RONNEBERGER, OLAF : 3D U-Net : learning dense volumetric segmentation from sparse annotation. In International conference on medical image computing and computer-assisted intervention, pages 424–432. Springer, 2016.</a></p>

<p><a href="https://arxiv.org/pdf/1606.00915.pdf">[6]<a name="6"></a> CHEN, LIANG-CHIEH AND PAPANDREOU, GEORGE AND KOKKINOS, IASONAS AND MURPHY, KEVIN AND YUILLE, ALAN L : Deeplab : Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence, 40(4):834–848, 2017.</a></p>

<p><a href="https://arxiv.org/pdf/1601.06733.pdf">[7]<a name="7"></a> CHENG, JIANPENG AND DONG, LI AND LAPATA, MIRELLA : Long short-term memory-networks for machine reading. arXiv preprint arXiv :1601.06733, 2016.</a></p>

<p><a href="Learning phrase representations using RNN encoderdecoder for statistical machine translation">[8]<a name="8"></a> CHO, KYUNGHYUN AND VAN MERRIËNBOER, BART AND GULCEHRE, CAGLAR AND BAHDANAU, DZMITRY AND BOUGARES, FETHI AND SCHWENK, HOLGER AND BENGIO, YOSHUA : Learning phrase representations using RNN encoderdecoder for statistical machine translation. arXiv preprint arXiv :1406.1078, 2014.</a></p>

<p><a href="http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf">[9]<a name="9"></a> CHRISTOPHER M. BISHOP : Pattern Recognition and Machine Learning (Information Science and Statistics). SpringerVerlag, 2006.</a></p>

<p>[10]<a name="10"></a> CIREGAN, DAN AND MEIER, UELI AND SCHMIDHUBER, JÜRGEN : Multi-column deep neural networks for image classification. In 2012 IEEE conference on computer vision and pattern recognition, pages 3642–3649. IEEE, 2012.</p>

<p>[11]<a name="11"></a> DEVLIN, JACOB AND CHANG, MING-WEI AND LEE, KENTON AND TOUTANOVA, KRISTINA : Bert : Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv :1810.04805, 2018.</p>

<p>[12]<a name="12"></a> DOERSCH, CARL : Tutorial on variational autoencoders. arXiv preprint arXiv :1606.05908, 2016.</p>

<p>[13]<a name="13"></a> GIRSHICK, ROSS : Fast r-cnn. In Proceedings of the IEEE international conference on computer vision, pages 1440–1448, 2015.</p>

<p>[14]<a name="14"></a> GIRSHICK, ROSS AND DONAHUE, JEFF AND DARRELL, TREVOR AND MALIK, JITENDRA : Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 580–587, 2014.</p>

<p>[15]<a name="15"></a> GOODFELLOW, IAN AND POUGET-ABADIE, JEAN AND MIRZA, MEHDI AND XU, BING AND WARDE-FARLEY, DAVID AND OZAIR, SHERJIL AND COURVILLE, AARON AND BENGIO, YOSHUA : Generative adversarial nets. Advances in neural information processing systems, 27, 2014.</p>

<p>[16]<a name="16"></a> HE, KAIMING AND GKIOXARI, GEORGIA AND DOLLÁR, PIOTR AND GIRSHICK, ROSS : Mask r-cnn. In Proceedings of the IEEE international conference on computer vision, pages 2961–2969, 2017.</p>

<p>[17]<a name="17"></a> HE, KAIMING AND ZHANG, XIANGYU AND REN, SHAOQING AND SUN, JIAN : Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.</p>

<p>[18]<a name="18"></a> HOCHREITER, SEPP AND SCHMIDHUBER, JÜRGEN : Long short-term memory. Neural computation, 9(8):1735–1780, 1997.</p>

<p>[19]<a name="19"></a> HOWARD, ANDREW G AND ZHU, MENGLONG AND CHEN, BO AND KALENICHENKO, DMITRY AND WANG, WEIJUN AND WEYAND, TOBIAS AND ANDREETTO, MARCO AND ADAM, HARTWIG : Mobilenets : Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv :1704.04861, 2017.</p>

<p>[20]<a name="20"></a> HUANG, GAO AND LIU, ZHUANG AND VAN DER MAATEN, LAURENS AND WEINBERGER, KILIAN Q : Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4700–4708, 2017.</p>

<p><a href="http://www.deeplearningbook.org">[21]<a name="21"></a> IAN GOODFELLOW, YOSHUA BENGIO ET AARON COURVILLE : Deep Learning. MIT Press, 2016.</a></p>

<p>[22]<a name="22"></a> IOFFE, SERGEY AND SZEGEDY, CHRISTIAN : Batch normalization : Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pages 448–456. PMLR, 2015.</p>

<p>[23]<a name="23"></a> ISENSEE, FABIAN AND JAEGER, PAUL F AND KOHL, SIMON AA AND PETERSEN, JENS AND MAIER-HEIN, KLAUS H : nnU-Net : a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2):203–211, 2021.</p>

<p>[24]<a name="24"></a> KARRAS, TERO AND LAINE, SAMULI AND AILA, TIMO : A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4401–4410, 2019.</p>

<p>[25]<a name="25"></a> KINGMA, DIEDERIK P AND WELLING, MAX : Auto-encoding variational bayes. arXiv preprint arXiv :1312.6114, 2013.</p>

<p>[26]<a name="26"></a> KRIZHEVSKY, ALEX AND SUTSKEVER, ILYA AND HINTON, GEOFFREY E : Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25:1097–1105, 2012.</p>

<p>[27]<a name="27"></a> LECUN, YANN AND BOTTOU, LÉON AND BENGIO, YOSHUA AND HAFFNER, PATRICK : Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.</p>

<p>[28]<a name="28"></a> LIU, WEI AND ANGUELOV, DRAGOMIR AND ERHAN, DUMITRU AND SZEGEDY, CHRISTIAN AND REED, SCOTT AND FU, CHENG-YANG AND BERG, ALEXANDER C : Ssd : Single shot multibox detector. In European conference on computer vision, pages 21–37. Springer, 2016.</p>

<p>[29]<a name="29"></a> LONG, JONATHAN AND SHELHAMER, EVAN AND DARRELL, TREVOR : Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431–3440, 2015.</p>

<p>[30]<a name="30"></a> LUONG, MINH-THANG AND PHAM, HIEU AND MANNING, CHRISTOPHER D : Effective approaches to attention-based neural machine translation. arXiv preprint arXiv :1508.04025, 2015.</p>

<p>[31]<a name="31"></a> MIKOLOV, TOMAS AND CHEN, KAI AND CORRADO, GREG AND DEAN, JEFFREY : Efficient estimation of word representations in vector space. arXiv preprint arXiv :1301.3781, 2013.</p>

<p>[32]<a name="32"></a> MILLETARI, FAUSTO AND NAVAB, NASSIR AND AHMADI, SEYED-AHMAD : V-net : Fully convolutional neural networks for volumetric medical image segmentation. In 2016 fourth international conference on 3D vision (3DV), pages 565–571. IEEE, 2016.</p>

<p>[33]<a name="33"></a> MIRZA, MEHDI AND OSINDERO, SIMON : Conditional generative adversarial nets. arXiv preprint arXiv :1411.1784, 2014.</p>

<p>[34]<a name="34"></a> PASZKE, ADAM AND CHAURASIA, ABHISHEK AND KIM, SANGPIL AND CULURCIELLO, EUGENIO : Enet : A deep neural network architecture for real-time semantic segmentation. arXiv preprint arXiv :1606.02147, 2016.</p>

<p>[35]<a name="35"></a> PLAUT, ELAD : From principal subspaces to principal components with linear autoencoders. arXiv preprint arXiv :1804.10253, 2018.</p>

<p>[36]<a name="36"></a> RADFORD, ALEC AND METZ, LUKE AND CHINTALA, SOUMITH : Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv :1511.06434, 2015.</p>

<p>[37]<a name="37"></a> RADFORD, ALEC AND NARASIMHAN, KARTHIK AND SALIMA</p>

<p>[38]<a name="38"></a> RADFORD, ALEC AND WU, JEFFREY AND CHILD, REWON AND LUAN, DAVID AND AMODEI, DARIO AND SUTSKEVER, ILYA AND OTHERS : Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.</p>

<p>[39]<a name="39"></a> REDMON, JOSEPH AND DIVVALA, SANTOSH AND GIRSHICK, ROSS AND FARHADI, ALI : You only look once : Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 779–788, 2016.</p>

<p>[40]<a name="40"></a> REDMON, JOSEPH AND FARHADI, ALI : YOLO9000 : better, faster, stronger. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7263–7271, 2017.</p>

<p>[41]<a name="41"></a> REN, SHAOQING AND HE, KAIMING AND GIRSHICK, ROSS AND SUN, JIAN : Faster r-cnn : Towards real-time object detection with region proposal networks. Advances in neural information processing systems, 28:91–99, 2015.</p>

<p>[42]<a name="42"></a> RONNEBERGER, OLAF AND FISCHER, PHILIPP AND BROX, THOMAS : U-net : Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention, pages 234–241. Springer, 2015.</p>

<p>[43]<a name="43"></a> SIMONYAN, KAREN AND ZISSERMAN, ANDREW : Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv :1409.1556, 2014.</p>

<p>[44]<a name="44"></a> SOHN, KIHYUK AND LEE, HONGLAK AND YAN, XINCHEN : Learning structured output representation using deep conditional generative models. Advances in neural information processing systems, 28:3483–3491, 2015.</p>

<p><a href="https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">[45]<a name="45"></a> SRIVASTAVA, NITISH AND HINTON, GEOFFREY AND KRIZHEVSKY, ALEX AND SUTSKEVER, ILYA AND SALAKHUTDINOV, RUSLAN : Dropout : a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):1929–1958, 2014.</a></p>

<p>[46]<a name="46"></a> SZEGEDY, CHRISTIAN AND LIU, WEI AND JIA, YANGQING AND SERMANET, PIERRE AND REED, SCOTT AND ANGUELOV, DRAGOMIR AND ERHAN, DUMITRU AND VANHOUCKE, VINCENT AND RABINOVICH, ANDREW : Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.</p>

<p>[47]<a name="47"></a> VASWANI, ASHISH AND SHAZEER, NOAM AND PARMAR, NIKI AND USZKOREIT, JAKOB AND JONES, LLION AND GOMEZ, AIDAN N AND KAISER, ŁUKASZ AND POLOSUKHIN, ILLIA : Attention is all you need. In Advances in neural information processing systems, pages 5998–6008, 2017.</p>

<p>[48]<a name="48"></a> WANG, YI AND LUO, ZHIMING AND JODOIN, PIERRE-MARC : Interactive deep learning method for segmenting moving objects. Pattern Recognition Letters, 96:66–75, 2017.</p>

<p>[49]<a name="49"></a> XU, KELVIN AND BA, JIMMY AND KIROS, RYAN AND CHO, KYUNGHYUN AND COURVILLE, AARON AND SALAKHUDINOV, RUSLAN AND ZEMEL, RICH AND BENGIO, YOSHUA : Show, attend and tell : Neural image caption generation with visual attention. In International conference on machine learning, pages 2048–2057. PMLR, 2015.</p>

<p>[50]<a name="50"></a> ZEILER, MATTHEW D AND FERGUS, ROB : Visualizing and understanding convolutional networks. In European conference on computer vision, pages 818–833. Springer, 2014.</p>

        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=https://www.antoinetheberge.ca/teaching/2021-spring-ift780" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https://www.antoinetheberge.ca/teaching/2021-spring-ift780" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.antoinetheberge.ca/teaching/2021-spring-ift780" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/antoinetheb"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="https://www.antoinetheberge.ca/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Antoine Théberge. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://www.antoinetheberge.ca/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

